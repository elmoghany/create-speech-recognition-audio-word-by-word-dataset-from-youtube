#pre-requisites
1. download whisper-tiny.en model from hugging face
2. put its files under models/whisper-tiny.en

#RUN

To run the code type
python main.py

#1) getAudio
gets audio from the link specified in main.py
it also samples it at 16Khz

#2) getXMLSubtitle
gets auto generated subtitle by google speech recognition that is present in the video captions CC in the format of XML

#3) xMLToWordByWordSRT
convert the xml file into srt file while insuring no data is missed during the convertion. Ensure having a correct SRT file from timing stand point and from sentences stand point
After the conversion, it converts the sentences into words and assign each word the actual timing corresponds to the audio

#4) pysrtModifications
modify the srt file timing by adding 0.2 seconds to the end of each word to ensure words are not being cut out

#5) skipWords
Skip words that is not important for the training to ensure the model is being trained on the exact words needed
i.e. ignore you, me, my, i, to, um, is, are ...etc

#6) splitAudioWordByWord
Split the whole audio clip based on the srt files while skipping the words in the skipWords file
After that it generate metadata.csv file with 2 columns. 1st is path which includes the path of the audio files. 2nd is transcription which includes the corresponding transcription for each audio file

#7) modelFineTuning
fine tuning training for the whisper model on those words generated by the youtube links
